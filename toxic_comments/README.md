# Проект для «Викишоп» с BERT

## Описание проекта
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 
Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.
Построим модель со значением метрики качества *F1* не меньше 0.75.

## Описание данных
-	`text` — содержит текст комментария
Целевой признак:
-    `toxic`
Данные находятся в файле: `toxic_comments.csv` 

## Содержание проекта

### Решение задачи классификации с помощью лемматизации и векторизации
- лемматизации производилась с помощью библиотек Spacy и nltk
- векторизации с помощью TfidfVectorizer
**Результат**
- Были обучены 3 модели (`LogisticRegression`, `DecisionTreeClassifier`, `CatBoostClassifier`) с подбором гиперпараметров;
- Лучшей моделью оказалась `CatBoostClassifier` с метрикой `f1_score = 0.756` на тренировочной выборке и `f1_score = 0.761` на валидационной;
- Время обучения модели - 1.17 часа;
- Полученное значение `f1_score` на валидационной выборке, удовлетворяет требованию - быть не менее 0.75.

### Решение задачи классификации с помощью нейросети DistilBERT
- Модель DistilBert справилась с классификацией лучше, ее метрика на тренировочной выборке `f1_score=0.8829`, а на валидационной `f1_score=0.8147`.
- Время обучения модели 3.67 часа.

## Вывод
1. Загружены данные с комментариями магазина «Викишоп».
2. Был проведен анализ данных в ходе которого не было обнаружено пропусков и дубликатов.
3. Удален дублирующий столбец `Unnamed: 0` содержащий индексы.
4. Были подготовлены и лемматизированы данные с помощью библиотеки `spacy`, для дальнейшего обучения модели машинного обучения.
5. Были обучены 3 модели (`LogisticRegression`, `DecisionTreeClassifier`, `CatBoostClassifier`) с подбором гиперпараметров:
    - Лучшей моделью оказалась `CatBoostClassifier` с метрикой `f1_score = 0.756` на тренировочной выборке и `f1_score = 0.761` на валидационной;
    - Время обучения модели - 1.17 часа;
    - Полученное значение `f1_score` на валидационной выборке, удовлетворяет требованию - быть не менее 0.75.
6. Была обучена 1 модель с нейросетью DistilBert:
    - Метрика на тренировочной выборке `f1_score=0.8829`, а на валидационной `f1_score=0.8147`;
    - Время обучения модели 3.67 часа;
    - Полученное значение `f1_score` на валидационной выборке, удовлетворяет требованию - быть не менее 0.75.

Использование моделей с нейросетями помогает улучшить качество модели, но требует больше временных затрат (примерно в 3 раза), а также ресурсов компьютера (без cuda ядер обучение длилось бы в разы дольше).
